{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcdbbc0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Eng. Daniel Vieira\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Parsing nodes: 100%|██████████| 1/1 [00:00<00:00, 14.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF carregado com sucesso.\n",
      "* Running on local URL:  http://127.0.0.1:7862\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7862/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import gradio as gr\n",
    "from typing import List\n",
    "from llama_index.core import SimpleDirectoryReader, StorageContext, VectorStoreIndex\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
    "from llama_index.llms.groq import Groq\n",
    "from llama_index.core.memory import ChatSummaryMemoryBuffer\n",
    "import chromadb\n",
    "from tempfile import TemporaryDirectory\n",
    "from PyPDF2 import PdfReader\n",
    "\n",
    "# Wrapper de embedding compatível com ChromaDB\n",
    "class ChromaEmbeddingWrapper:\n",
    "    def __init__(self, model_name: str):\n",
    "        self.model = HuggingFaceEmbedding(model_name=model_name)\n",
    "\n",
    "    def __call__(self, input: List[str]) -> List[List[float]]:\n",
    "        return self.model.embed_documents(input)\n",
    "\n",
    "# Inicializa modelos de embedding\n",
    "embed_model = HuggingFaceEmbedding(model_name='intfloat/multilingual-e5-large')\n",
    "embed_model_chroma = ChromaEmbeddingWrapper(model_name='intfloat/multilingual-e5-large')\n",
    "\n",
    "# Inicializa ChromaDB\n",
    "chroma_client = chromadb.PersistentClient(path='./chroma_db')\n",
    "collection_name = 'documentos_serenatto'\n",
    "chroma_collection = chroma_client.get_or_create_collection(\n",
    "    name=collection_name,\n",
    "    embedding_function=embed_model_chroma\n",
    ")\n",
    "\n",
    "vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "\n",
    "# Inicializa LLM da Groq\n",
    "Groq_api = os.environ.get(\"GROQ_API_KEY\")\n",
    "llms = Groq(model='llama3-70b-8192', api_key='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')\n",
    "\n",
    "# Estados globais\n",
    "document_index = None\n",
    "chat_engine = None\n",
    "\n",
    "# Carregamento único do PDF\n",
    "def carregar_pdf_inicial():\n",
    "    global document_index, chat_engine\n",
    "\n",
    "    try:\n",
    "        with TemporaryDirectory() as tmpdir:\n",
    "            pdf_path = \"documentos/serenatto.pdf\"\n",
    "            text = \"\"\n",
    "            reader = PdfReader(pdf_path)\n",
    "            for page in reader.pages:\n",
    "                text += page.extract_text() or \"\"\n",
    "\n",
    "            with open(os.path.join(tmpdir, \"temp.txt\"), \"w\", encoding=\"utf-8\") as f:\n",
    "                f.write(text)\n",
    "\n",
    "            documentos = SimpleDirectoryReader(input_dir=tmpdir)\n",
    "            docs = documentos.load_data()\n",
    "\n",
    "            node_parser = SentenceSplitter(chunk_size=1200)\n",
    "            nodes = node_parser.get_nodes_from_documents(docs, show_progress=True)\n",
    "\n",
    "            document_index = VectorStoreIndex(nodes, storage_context=storage_context, embed_model=embed_model)\n",
    "\n",
    "            memory = ChatSummaryMemoryBuffer(llm=llms, token_limit=256)\n",
    "\n",
    "            chat_engine = document_index.as_chat_engine(\n",
    "                chat_mode='context',\n",
    "                llm=llms,\n",
    "                memory=memory,\n",
    "                system_prompt='''Você é especialista em cafés da loja Serenatto. Responda de forma simpática e natural sobre os grãos disponíveis.'''\n",
    "            )\n",
    "\n",
    "            print(\"PDF carregado com sucesso.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao carregar PDF: {e}\")\n",
    "\n",
    "# Função de chat\n",
    "def converse_com_bot(message, chat_history):\n",
    "    global chat_engine\n",
    "\n",
    "    if chat_engine is None:\n",
    "        return \"Erro: o bot ainda não está pronto.\", chat_history\n",
    "\n",
    "    response = chat_engine.chat(message)\n",
    "\n",
    "    if chat_history is None:\n",
    "        chat_history = []\n",
    "\n",
    "    chat_history.append({\"role\": \"user\", \"content\": message})\n",
    "    chat_history.append({\"role\": \"assistant\", \"content\": response.response})\n",
    "\n",
    "    return \"\", chat_history\n",
    "\n",
    "# Resetar conversa\n",
    "def resetar_chat():\n",
    "    global chat_engine\n",
    "    if chat_engine:\n",
    "        chat_engine.reset()\n",
    "    return []\n",
    "\n",
    "# Carregar PDF na inicialização\n",
    "carregar_pdf_inicial()\n",
    "\n",
    "# Interface Gradio\n",
    "with gr.Blocks() as app:\n",
    "    gr.Markdown(\"# ☕ Chatbot Serenatto – Especialista em Cafés\")\n",
    "\n",
    "    chatbot = gr.Chatbot(label=\"Conversa\", type=\"messages\")\n",
    "    msg = gr.Textbox(label='Digite a sua mensagem')\n",
    "    limpar = gr.Button('Limpar')\n",
    "\n",
    "    msg.submit(converse_com_bot, [msg, chatbot], [msg, chatbot])\n",
    "    limpar.click(resetar_chat, None, chatbot, queue=False)\n",
    "\n",
    "    app.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48f27b75",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install -q gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d36f135a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install -q llama-index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1729736",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install -q llama-index-embeddings-huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47c1e193",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install -q llama-index-vector-stores-chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b00e8b22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install -q  chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c1f6808",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install -q llama-index-llms-groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "533ec3aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install -q PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd414d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#llama-index\n",
    "#chromadb\n",
    "#PyPDF2\n",
    "#gradio\n",
    "#transformers\n",
    "#sentence-transformers\n",
    "#huggingface-hub\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
